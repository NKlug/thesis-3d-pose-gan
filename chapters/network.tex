\section{Network architecture}\label{sec:network}
\Todo[inline]{Mention root joint}
\begin{itemize}
	\item basic principle of gans
	\item Basic architecture used in the paper
	\item Mention batch norm not working with reference to other paper and communication with authors
	\item Projection and reprojection.
	\item Norm limb normalization
\end{itemize}

Assumptions:
\begin{enumerate}
	\item The camera is centered at the root joint.
	\item The distance between the camera is such that the length of the projected norm limb is $0.1$. 
\end{enumerate}
\begin{itemize}
	\item[(1)] All 2d data can be scaled in a way that a norm limb is of length 0.1. 
	Problems with correct camera distance, see section \ref{sec:z-shift-error}. 
	Problem when camera is perpendicular to the norm limb.
	\item[(2)] All data was captured with the same camera distance.
\end{itemize}

Generative Adversarial Networks (GANs) have first been presented by \citet{goodfellow14} in 2014.
The basic principle is two players playing a minimax game against each other.
One of the players, the \textit{discriminator} tries to guess whether the input comes from a real data distribution or a data distribution captured by the second player, the so called \textit{generator}. 
The generator's goal is to fool the discriminator, that is, to produce such elements that the probability of the discriminator making a mistake is maximal.
\citet{goodfellow14} have shown that this is the case if and only if the fake data distribution matches the real one.
In this case, the discriminator produces an output of $\frac{1}{2}$ for all inputs.

A (three dimensional) \textit{pose} is a collection of $n$ points in $\mathbb{R}^3$.

For the projection and re-projection of poses a pinhole camera model is used.
It has a focal length $f$ and is described by the perspective projection equation
\begin{equation}
	p = 
	\begin{pmatrix}
	x\\
	y
	\end{pmatrix}
	= \frac{f}{Z} \cdot 	
	\begin{pmatrix}
	X\\
	Y
	\end{pmatrix} \ ,
\end{equation}
where $P = (X, Y, Z)$ is a point in camera coordinates and p the projected point on the (virtual) image plane.
Throughout this work coordinates of 3D points will be denoted by capital letters and 2D points by lower case letters.

In general, the \textit{generator} $G$ is a neural network that produces \unsure{wording: elements or values?} elements from the distribution $P_{fake}$.
In the application of 3D human pose estimation the generator receives a projection of a 3D pose as input and outputs the corresponding 3D pose.
More precisely the generator only produces a depth offset $o_i$ for each joint in the input.
The entire pose can then be calculated by first calculating absolute depths:
\begin{equation}
	Z_i = \max \{f, Z + o_i\} \ .
\end{equation}
The clipping makes sure the points are re-projected in front of the camera.
\Todo{During training: $Z = 10$ and $f = 1$}
Afterwards the 2D points are re-projected along the projection rays:
\begin{equation}
	\begin{pmatrix}
	X_i\\
	Y_i
	\end{pmatrix} = \frac{Z_i}{f} \cdot
	\begin{pmatrix}
	x_i\\
	y_i
	\end{pmatrix}
\end{equation} 
The 3D pose is then given by $\{(X_i, Y_i, Z_i)~|~ 1 \leq i \leq n\}$.

In production the generation process would be over at this point but for training, 2D poses have to be sampled from the reprojected 3D pose.
The 3D poses are aligned with the origin and randomly rotated with azimuth angles between $0$ and $360$ and elevation between $0$ between $20$ degrees.
\Todo{When 2D poses are sampled, the extrinsic parameters of the synthetic camera model should match those of the real camera(s)}

The \textit{discriminator} $D$ is defined as a neural network that consumes real 2D poses from the distribution $P_{real}$ and fake 2D poses drawn from $P_{fake}$ and outputs a scalar value in $[0, 1]$.
A GAN can be formulated as as a minimax game with a value function $V(D, G)$ as follows \cite{goodfellow14}: 
\begin{equation}
	\min_G \max_D V(D, G) = \mathbb{E}_{r\sim P_{real}}(\log(D(r))) + \mathbb{E}_{p\sim P_{fake}}(\log(1 - D(p)))
\end{equation}

De facto loss functions for generator and discriminator:
\begin{align}
	\label{eq:generator-loss}
	loss_G &= \mathbb{E}_{p\sim P_{fake}}(\log(1 - D(p))) \\
	\label{eq:discriminator-loss}
	loss_D &= \mathbb{E}_{r\sim P_{real}}(\log(D(r))) + \mathbb{E}_{p\sim P_{fake}}(\log(1 - D(p)))
\end{align} 