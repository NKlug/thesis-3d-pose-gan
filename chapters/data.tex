\section{3D Human Pose Datasets}
\label{sec:data}

\begin{itemize}
	\item Common 3D datasets with 3D annotation. Very few annotated. Human3.6M, HumanEvaI/II, TotalCapture, SURREAL (synthetic), KTH Multiview Football II
	\item Motivation for training with 2D data only
	\item Different representations of poses (absolute points, angles, ...)?
	\item 32 joints model / 15 joint model !!!
	\item all joints and all activities as footnotes
\end{itemize}
 
notoriously
Whereas there are a lot of annotated human 2D pose estimation datasets (MPII, COCO Keypoints, PoseTrack, DensePose), there are only very few annotated 3D pose datasets. 
2D poses can be easily captured and annotated.
Only images are necessary for this.
As opposed to this, capturing ground truth data for 3D poses is notoriously harder.
For precise ground truth poses, a motion capture system is required which is not broadly available due to the high cost.
Though, this saves the effort of manual labeling.



In this work, human poses from the Human3.6M dataset \cite{ionescu14} is used for training and evaluation.
It comprises 3.6 million three dimensional human poses captured by four digital cameras and a motion capture system.
Within the dataset 11 subjects (6 male, 5 female) perform 15 different activities, such as walking, taking a photo, eating etc.\footnote{
	The 15 activities are: Giving Directions, Discussing, Eating, Greeting, Phoning, Posing, Purchasing, Sitting, Sitting down (on the ground), SmokinL, Taking a Photo, Waiting, Walking, Walking a Dog and Walking Together.
}
The poses are available in different parametrizations, such as Cartesian coordinates or Kinematic Parametrization.
Throughout this thesis, the 3D poses in the Cartesian coordinate systems of the four digital cameras are used (\texttt{D3\_Positions\_mono} in the dataset).
For those 3D poses, monocular 2D projections onto the cameras' image planes are also available which will also be used for evaluation.

\Todo{Find out what those points are}
The poses in the dataset consist of 32 joints.
In \cite{drover18} only 14 of those joints are used.\footnote{
The 14 joints are: heels, knees, hips, thorax, head, shoulders, elbows and wrists.
}
This work follows the same convention, with the only difference being that the pelvis (center point between hips) is added to those 14 joints.

Later, the system will also be evaluated on poses from the TotalCapture dataset \cite{trumble17}.
This dataset consists of about 1.9 million 3D poses.
One pose comprises 21 joints, among which are the same 15 joints that were selected for the Human3.6M dataset.

\subsection{Evaluation Metrics}
\Todo{Mention Joint Position Error (JPE)? Check with Section \ref{sec:x-shift-error}}
In the literature multiple different methods are used to quantitatively evaluate the estimated poses. 
Essentially most systems estimate the 3D poses in Cartesian coordinates \cite{drover18, chen17, bogo16, grinciunaite16, yasin16, wandt19, tome17, tekin16, tekin17, pavlakos17}.

For this parametrization the most commonly used metric is the \emph{Mean Per Joint Position Error (MPJPE)}.
It is the mean of the \emph{Joint Position Errors (JPE)} across all joints.
For a pose with $n$ joints, ground truth 3D joint positions $G_i$ and predicted positions $P_i$ it is defined as
\begin{equation}
\frac{1}{n} \sum_{i = 1}^{n}  \norm{G_i - P_i}_2 \ .
\end{equation}
The values for this metric are reported in millimeters.

As \citet{ionescu14} point out, the problem with this metric is that it is highly subject specific.
An estimated pose for a smaller person might be equally bad as for a taller person, but the MPJPE will be much lower for the former.
In order to circumvent this, they propose a Universal MPJPE (UMPJPE) which normalizes all poses to have the same dimensions (in their case the same limb lengths) before measuring the Euclidean distance.

While not broadly used, \citet{ionescu14} also suggest the \emph{Mean Per Joint Angle Error (MPJAE)}.
This metric measures the difference of the joint angles between the ground truth and predicted pose.
It is defined as
\begin{equation}
\frac{1}{m} \sum_{i = 1}^{m} \abs{\alpha_i - \beta_i \mod \pm 180\degree} \,
\end{equation}
where $m$ is the number of joint angles and $\alpha_i$ and $\beta_i$ the angles for the ground truth pose and the estimated pose.
Due to the lacking intuitiveness behind this metric and the straightforward conversion to Cartesian coordinates, although they make use of the Kinematic pose representation, \citet{jahangiri17} and \citet{zhou16_2} also report their results for the MPJPE metric.

\subsection{Evaluation Protocols}

For the MPJPE metric, multiple different evaluation protocols with minor variations have evolved.
Those vary between different datasets, but are also caused by different systems producing different outputs.


What most systems have in common is that they produce 3D poses only up to a scaling factor.
As for a 2D pose there is an infinite amount of 3D poses that project to the same pose, unless the absolute size of the 3D pose is known, the pose can not be estimated to have that exact size.
And even if that size is known, it is oftentimes easier to estimate poses normalized in size and then scale them to the desired output.

Unless the absolute size of the 3D pose is known   all models produce absolute 3D poses, but some only up to a scaling factor or alignment of joints.
Therefore, some modifications have to be made in order to measure the quality and allow a fair comparison to other approaches.
 
The most commonly used metric for evaluation is the \textit{Mean Per Joint Position Error} (MPJPE).



\subsubsection{Protocol 1}

This protocol is used under different names in slightly different variations in \cite{sun17, drover18, moreno-noguer16, yasin16, kostrikov14, tome17}.
The method commonly referred to as \textbf{Protocol 1} uses subjects S1, S5, S6, S7, S8 and S9 for training and S11 for testing.

Sometimes the train data is thinned out further by the elimination of similar poses \cite{yasin16}.
\citet{drover18} even completely leave out S8 for training.
It allows rigid alignment \cite{drover18, yasin16, kostrikov14, sun17, tome17, chen17} of the predicted poses to the ground truth data.


Most authors do not explicitly state which kind of rigid alignment is applied to the predicted poses.
Those who do mention a Procrustes Analysis \cite{sun17, tome17} or a Least Squares transformation \cite{kostrikov14}.
That basically allows kinds of translation, scaling and rotation can be applied in order to best fit the predicted poses to the ground truth data.

This approach is not very realistic though as in production there is no ground truth data the predicted poses can be fitted to.
A more realistic testing technique is presented in the Section \ref{sec:protocol2}.

In accordance with the code shipped with the Human3.6M dataset, \citet{sun17}, \citet{chen17} and \citet{moreno-noguer16} use only every \nth{64} frame of the available data for testing.



%\input{evaluation_protocols}
\begin{itemize}
	\item Dataset Human3.6m
	\item Original and augmented data
	\item Data used for training, evaluation and testing.
\end{itemize}
\subsubsection{Protocol 2}\label{sec:protocol2}

The second protocol found in the literature is \textbf{Protocol 2}.
In this case only S1, S5, S6, S7 and S8 are used for training, while test results are reported for S9 and S11.

Whereas \citet{sun17} only use every \nth{64} frame and \citet{moreno-noguer16} and \citet{bogo16} only use camera 3 for testing, most authors do not mention which poses exactly are used for testing.

This protocol only allows certain noninvasive changes to the predicted poses.
In general rigid alignment like a Procrustes Analysis is not allowed.
The degree of the changes applied to the predicted poses strongly depends on the model.
In a system that predicts absolute 3D poses usually no changes have to be made to the predicted poses in order to obtain meaningful results.
With only a monocular 2D projection of a pose, it is not possible to estimate the absolute 3D poses as there are multiple 3D poses which all have the same 2D projection.
Therefore many models \cite{martinez17, zhou18, zhou16, tekin16, pavlakos17} allow aligning two designated root joints (usually the central hip) of the predicted and the ground truth poses.
In cases where it is not possible to correctly estimate the global scale of the poses scaling is also allowed.
\citet{zhou18} do this by scaling the predicted poses such that "the mean limb length is identical to the average value of all training subjects".
This is still suboptimal because if the subjects have different mean limb lengths (which is the case) the error for a perfect prediction would not be 0.
A better way of scaling would be the following:

First, calculate the average limb length $L_s$ of all poses for each subject $s$.
Then, scale each predicted and ground truth pose in a way that the mean limb length is equal to $L_s$.

Because adjusting the ground truth data is not a good practice in general, in this thesis only the predicted poses are scaled to match $L_s$.

The scaling of the estimated 3D poses can be regarded as follows. Let $\alpha$ be the average limb lengths of the ground truth pose and $\beta$ be the one of the estimated poses.
Then the error is calculated in the following way:
\begin{align}
	\Delta d &= \frac{1}{n} \sum_{i = 1}^{n}  \norm{\alpha \frac{O_i}{\beta} - \alpha \frac{P_i}{\alpha}}_2 \\
	&=  \frac{1}{n} \sum_{i = 1}^{n} \abs{\alpha} \norm{\frac{O_i}{\beta} -\frac{P_i}{\alpha}}_2 \\
	&=  \abs{\alpha} \frac{1}{n} \sum_{i = 1}^{n} \norm{\frac{O_i}{\beta} -\frac{P_i}{\alpha}}_2 \ .
	\label{eq:protocol2-mpjpe-scaling}
\end{align}

This can be interpreted such that the MPJPE is first calculated for the poses with normalized average limb length and then scaled such that the original scale of the ground truth poses is represented. 

IMPORTANT: An MPJPE of approximately 5mm can be measured when comparing the scaled ground truth poses with the original ones (the standard deviation of the scaling factors is at $0.01$).!!!!

\Todo[inline]{Mention TotalCapture dataset briefly. Also compare Protocol 1 and 2: "Rotation is the key difference while rotation and translation of the Procrustes transformation might also be better"}