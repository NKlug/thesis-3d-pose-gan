\section{Conclusion}
In this thesis, the 2D to 3D human pose estimation system by \citet{drover18} has been analyzed with respect to the applied pose normalization.
In their work "Can 3D Pose Be Learned from 2D Projections Alone?", the authors propose a Generative Adversarial Network in which the generator estimates the depths for each of the 2D input pose's joints.
With those depths, a 3D pose can be obtained by re-projecting the 2D pose using the perspective projection equation.
The core feature of the system is that it can be trained solely using real 2D poses.
No 3D ground truth data is required.
For that, random projections of the estimated 3D poses are fed to the discriminator, which tries to distinguish between those and real 2D poses.

\autoref{sec:data} is about 3D human pose datasets, in particular the Human3.6M \cite{ionescu14} dataset.
The two evaluation protocols used in the context of this dataset were presented and discussed.
As the implementation of those protocols varies in literature, a noninvasive way of transforming the estimated poses was suggested for Protocol 2.
This transformation allows aligning two predefined root joints and scaling the poses to match the average limb length of the ground truth poses for each subject in the test dataset.
This comes close to the transformations that can be applied during application, and thus gives good insight about the quality of the poses in that scenario.

In \autoref{sec:evaluation}, a rebuilt version of the system has been evaluated for different data configurations.
The results reported by \citet{drover18} could only be reproduced up to a $6.8$mm margin when trained on synthetic 2D poses with an overall MPJPE of $41.0$mm for Protocol 1 (which allows rigid alignment through a Procrustes Transformation) and $54.8$mm for Protocol 2.
For the monocular 2D poses included in the Human3.6M dataset, the same results could only be achieved for Protocol 1; for Protocol 2 the MPJPE increased to $80.4$mm.
When trained with those poses in addition to the synthetic poses, the error could be reduced by about $1$cm.

In \autoref{sec:loss-function-modification} an alternative loss function for the generator has been suggested.
Humans have a bilaterally symmetrical skeleton with many limbs known to have equal lengths.
The suggested loss function punishes the generator if it produces symmetric limbs of different lengths, by adding the difference of two symmetric limbs to the standard GAN loss for the generator.
For training, the influence of the new term was increased over time.
With the new loss, the MPJPE could be reduced from $54.8$mm to $50.7$mm for Protocol 2.
This equals an improvement of more than $7\%$.

In \autoref{sec:effects-of-normalization}, the effects of pose normalization on the proposed system have been analyzed theoretically and experimentally.
The input poses are expected to be normalized in scale and location.
It has been shown that the normalization in location introduces a major error to the system, that increases for 2D poses having larger offsets from the camera's center.
Experimental results confirmed the theoretical lower bound.
If the need for normalization in scale originates from a varying focal lengths of the camera, there is no error.
On the other hand, if the poses have to be re-scaled due to a varying camera distance, an additional error can be found.
As this error is relatively small, especially for small variations, it should be negligible in most applications.

In the last section, \autoref{sec:network-adjusting}, the system suggested by \citet{drover18} has been modified to compensate the effects of pose normalization through alignment.
When the generator receives poses that are only normalized in scale, but not location, and re-projects those poses correctly into three dimensions, an almost constant performance for poses with all offsets could be achieved.
For poses that are $60^{\circ}$ off the camera center, in the modified system the MPJPE only increases by about $15$mm, compared to the previous $340$mm.