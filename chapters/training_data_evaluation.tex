\section{Evaluation on different datasets}
\label{sec:evaluation}

\unsure[inline]{If the thesis is too short (or maybe anyways) add protocol 1 evaluation}

In this section the model's performance will be analyzed for different configurations of training and test data.
For training the Adam Optimizer \cite{kingma17} with an initial learning rate of $0.0002$ and $\beta_1 = 0.5$ is used for both generator and discriminator.
This particular choice of $\beta_1$ has shown to result in faster convergence.
Like in the work by \citet{drover18}, the data is split up into batches of 32768 poses for training.
Generator and discriminator are trained alternately with the same batch of poses.
Before adjusting the networks' parameters, adaptive gradient clipping is applied  \cite[Section~3.2.1]{chorowski14}.

\begin{itemize}
	\item Results for self created data
	\item Results for original 2d data
\end{itemize}

\subsection{Results of the Original System}
\begin{itemize}
	\item Results of original system on augmented and real data.
	\item Results per action and average
	\item Results for real 2D data
\end{itemize}


\Todo[inline]{Compare sampled data error and error on real 2D poses from the dataset} 
\subsection{Different errors for different sets of joints}
Using only 15 joints yields a much lower MPJPE than using 32 joints. Reasons: ...	
From now on all numbers are calculated for 15 joint poses.

\subsection{Training with 1:1 mix of augmented and real data}
Important: Generator should output the same "kind" of data as the "real" data the discriminator receives.
Improvements of evaluation on real 2D data. 
This shows that the system is expected to perform well in scenarios where it is trained with data it should later infer.
Results for original data get better



\subsection{Training with augmented cameras similar to the real cameras}
Performance of system with cameras similar to the real cameras.
Results for real 2D data.